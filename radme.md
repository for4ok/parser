# Проект: Сбор цитат с сайта quotes.toscrape.com

## Описание проекта

Этот проект предназначен для автоматизированного сбора цитат, авторов и связанных тегов 
с сайта [quotes.toscrape.com](https://quotes.toscrape.com/). Данные сохраняются в формате JSON, 
что позволяет легко использовать их для последующего анализа, построения приложений или визуализаций.

---

## Задачи проекта

1. **Извлечь** данные о цитатах с сайта.
2. **Сохранить** собранные данные в формате JSON.
3. **Организовать код** так, чтобы его можно было использовать и модифицировать в будущем.

---

## Что было сделано

1. **Выбор источника данных:** Был выбран открытый учебный сайт [quotes.toscrape.com](https://quotes.toscrape.com/), 
так как он предоставляет упорядоченную структуру данных для парсинга и учебного применения.
2. **Написание кода для сбора данных:** Используя библиотеки `requests` и `BeautifulSoup`, мы написали Python-скрипт, 
который загружает страницы, парсит HTML и извлекает данные о цитатах.
3. **Организация цикла для нескольких страниц:** Сайт имеет несколько страниц, и для их автоматического перебора был 
реализован цикл, который переходит на следующую страницу до тех пор, пока на странице есть данные.
4. **Форматирование данных в JSON:** Все собранные данные о цитатах были структурированы и сохранены в `quotes.json`, 
что делает данные удобными для работы с ними в будущем.

---

## Источник данных

- **Источник:** [quotes.toscrape.com](https://quotes.toscrape.com/)
- **Тип данных:** Текстовые цитаты, имена авторов, и связанные с цитатами теги.
- **Формат хранения:** JSON

---

## Как осуществлялся сбор

1. **Запросы к страницам:** Для загрузки HTML-кода использовалась библиотека `requests`.
2. **Парсинг HTML:** Для извлечения данных из HTML использовалась библиотека `BeautifulSoup`, позволяющая легко 
находить нужные теги и извлекать текст.
3. **Пагинация:** Реализован переход на следующую страницу с помощью цикла, который добавляет номер страницы к URL.
4. **Сохранение данных:** Все данные о цитатах собирались в виде списка Python-словарей и затем сохранялись в файл JSON.

---

## Почему был выбран тот или иной метод/инструмент

- **`requests`** — Эта библиотека позволяет просто и эффективно загружать страницы, управлять заголовками запросов и 
- обрабатывать ответы от сервера. Использовать ее было проще, чем, например, Selenium, так как на данном сайте нет 
- сложных JavaScript-элементов.
  
- **`BeautifulSoup`** — Библиотека BeautifulSoup делает HTML-код доступным для навигации и анализа. В данном случае, 
- это упрощенный способ поиска нужных элементов (`div`, `span`, `a` и т.д.) по CSS-классам и атрибутам. BeautifulSoup
- подходит лучше, чем альтернативы (например, lxml), для небольших проектов, где важна простота и читаемость кода.

- **JSON для хранения данных** — Формат JSON выбран благодаря его удобству для структурированного хранения и 
- возможности легкого использования в других приложениях или программах для анализа данных.

---

## Как запустить проект

1. Убедитесь, что у вас установлен Python.
2. Установите необходимые библиотеки с помощью команды:
   ```bash
   pip install requests beautifulsoup4